{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EVARIST-DEV/EVARIST-DEV.github.io/blob/main/facerecognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEB0A71UYhXE"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AL2g-jtYaVQ7"
      },
      "outputs": [],
      "source": [
        "!pip install  opencv-python matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tBr5m5Hs-3v"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9tpb_4dtF86"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten\n",
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sipT_K-etNp_"
      },
      "source": [
        "gpu growth setup\n",
        "**bold text**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvwB1RX6tVd7"
      },
      "outputs": [],
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_yzp6IGyDQU"
      },
      "source": [
        "**setup paths**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVigQkGYx-wv"
      },
      "outputs": [],
      "source": [
        "POS_PATH = os.path.join('data', 'positive')\n",
        "NEG_PATH = os.path.join('data', 'negative')\n",
        "ANC_PATH = os.path.join('data', 'anchor')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3KhLqALzaKg"
      },
      "outputs": [],
      "source": [
        "#the directories\n",
        "os.makedirs(POS_PATH, exist_ok=True)\n",
        "os.makedirs(NEG_PATH, exist_ok=True)\n",
        "os.makedirs(ANC_PATH, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0JN1S1-hbdW"
      },
      "source": [
        "**labelled data set of faces from umass.edu**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xg_tBJrhWTk",
        "outputId": "7cdab563-cfcd-4ac3-9b8f-355a3024809e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tar: lfw.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n"
          ]
        }
      ],
      "source": [
        "# Uncompress Tar GZ Labelled Faces in the Wild Dataset\n",
        "!tar -xf lfw.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "UNvGTw_nzXI5",
        "outputId": "04d67853-017b-4769-e232-1e1f09d465c3"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-b7ea30580a6b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Move LFW Images to the following repository data/negative\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lfw'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lfw'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mEX_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lfw'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mNEW_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNEG_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'lfw'"
          ]
        }
      ],
      "source": [
        "# Move LFW Images to the following repository data/negative\n",
        "for directory in os.listdir('lfw'):\n",
        "    for file in os.listdir(os.path.join('lfw', directory)):\n",
        "        EX_PATH = os.path.join('lfw', directory, file)\n",
        "        NEW_PATH = os.path.join(NEG_PATH, file)\n",
        "        os.replace(EX_PATH, NEW_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTXjkpxl2VI8"
      },
      "outputs": [],
      "source": [
        "# Import uuid library to generate unique image names\n",
        "import uuid\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlcAcN7H2ZMD"
      },
      "outputs": [],
      "source": [
        "os.path.join(ANC_PATH, '{}.jpg'.format(uuid.uuid1()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "poOzw4xn2b1m"
      },
      "outputs": [],
      "source": [
        "# Establish a connection to the webcam\n",
        "cap = cv2.VideoCapture(4)\n",
        "while cap.isOpened():\n",
        "    frame = cap.read()\n",
        "    ret = cap.read()\n",
        "\n",
        "    # Cut down frame to 250x250px\n",
        "    frame = frame[120:120+250,200:200+250, :]\n",
        "\n",
        "    # Collect anchors\n",
        "    if cv2.waitKey(1) & 0XFF == ord('a'):\n",
        "        # Create the unique file path\n",
        "        imgname = os.path.join(ANC_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
        "        # Write out anchor image\n",
        "        cv2.imwrite(imgname, frame)\n",
        "\n",
        "    # Collect positives\n",
        "    if cv2.waitKey(1) & 0XFF == ord('p'):\n",
        "        # Create the unique file path\n",
        "        imgname = os.path.join(POS_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
        "        # Write out positive image\n",
        "        cv2.imwrite(imgname, frame)\n",
        "\n",
        "    # Show image back to screen\n",
        "    cv2.imshow('Image Collection', frame)\n",
        "\n",
        "    # Breaking gracefully\n",
        "    if cv2.waitKey(1) & 0XFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release the webcam\n",
        "cap.release()\n",
        "# Close the image show frame\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llEMq-kGn_TD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2hO3gqd2jyZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "#plt.imshow(frame[120:120+250,200:200+250, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_I3KR7g7GJYu"
      },
      "outputs": [],
      "source": [
        "anchor = tf.data.Dataset.list_files(ANC_PATH+'\\*.jpg').take(300)\n",
        "positive = tf.data.Dataset.list_files(POS_PATH+'\\*.jpg').take(300)\n",
        "negative = tf.data.Dataset.list_files(NEG_PATH+'\\*.jpg').take(300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIA236-7On1a"
      },
      "outputs": [],
      "source": [
        "dir_test = anchor.as_numpy_iterator()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgNz3tCT-4XZ"
      },
      "source": [
        "**Preprocessing - Scale and Resize**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jorRk5028yjW"
      },
      "outputs": [],
      "source": [
        "def preprocess(file_path):\n",
        "\n",
        "    # Read in image from file path\n",
        "    byte_img = tf.io.read_file(file_path)\n",
        "    # Load in the image\n",
        "    img = tf.io.decode_jpeg(byte_img)\n",
        "\n",
        "    # Preprocessing steps - resizing the image to be 100x100x3\n",
        "    img = tf.image.resize(img, (100,100))\n",
        "    # Scale image to be between 0 and 1\n",
        "    img = img / 255.0\n",
        "\n",
        "    # Return image\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnT05hdj_LvU"
      },
      "outputs": [],
      "source": [
        "img = preprocess('data\\\\anchor\\\\a4e73462-135f-11ec-9e6e-a0cec8d2d278.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jN3ViQwh_LqR"
      },
      "outputs": [],
      "source": [
        "img.numpy().max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3llzAp6M_er2"
      },
      "outputs": [],
      "source": [
        "dataset.map(preprocess)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSlPMzcd_je4"
      },
      "source": [
        "** Create Labelled Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUljIKEh_ifM"
      },
      "outputs": [],
      "source": [
        "positives = tf.data.Dataset.zip((anchor, positive, tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
        "negatives = tf.data.Dataset.zip((anchor, negative, tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
        "data = positives.concatenate(negatives)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNeiT-kq_wi7"
      },
      "outputs": [],
      "source": [
        "samples = data.as_numpy_iterator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJzzRqCV_3C9"
      },
      "outputs": [],
      "source": [
        "exampple = samples.next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkRkEDBx_7w6"
      },
      "outputs": [],
      "source": [
        "exampple"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWCQIETFAAWr"
      },
      "source": [
        "**Build Train and Test Partition**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZ6yzPOgAHyJ"
      },
      "outputs": [],
      "source": [
        "def preprocess_twin(input_img, validation_img, label):\n",
        "    return(preprocess(input_img), preprocess(validation_img), label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpXLWOe_AMQT"
      },
      "outputs": [],
      "source": [
        "res = preprocess_twin(*exampple)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1P4h80DAPBK"
      },
      "outputs": [],
      "source": [
        "plt.imshow(res[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmI8SC8eARRq"
      },
      "outputs": [],
      "source": [
        "res[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91ga_mOSAXcn"
      },
      "outputs": [],
      "source": [
        "# Build dataloader pipeline\n",
        "data = data.map(preprocess_twin)\n",
        "data = data.cache()\n",
        "data = data.shuffle(buffer_size=10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_vqDzxIAbeN"
      },
      "outputs": [],
      "source": [
        "# Training partition\n",
        "train_data = data.take(round(len(data)*.7))\n",
        "train_data = train_data.batch(16)\n",
        "train_data = train_data.prefetch(8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ReBf4d-ZAe-R"
      },
      "outputs": [],
      "source": [
        "# Testing partition\n",
        "test_data = data.skip(round(len(data)*.7))\n",
        "test_data = test_data.take(round(len(data)*.3))\n",
        "test_data = test_data.batch(16)\n",
        "test_data = test_data.prefetch(8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAXnbmm_AmMt"
      },
      "source": [
        "**Build Embedding Layer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e46SI-t2AkD4"
      },
      "outputs": [],
      "source": [
        "inp = Input(shape=(100,100,3), name='input_image')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iN_T_nvMAzsq"
      },
      "outputs": [],
      "source": [
        "c1 = Conv2D(64, (10,10), activation='relu')(inp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KzIin3pA5Hw"
      },
      "outputs": [],
      "source": [
        "m1 = MaxPooling2D(64, (2,2), padding='same')(c1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0qEWLTrA8Oj"
      },
      "outputs": [],
      "source": [
        "c2 = Conv2D(128, (7,7), activation='relu')(m1)\n",
        "m2 = MaxPooling2D(64, (2,2), padding='same')(c2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtpoMHELBA_o"
      },
      "outputs": [],
      "source": [
        "c3 = Conv2D(128, (4,4), activation='relu')(m2)\n",
        "m3 = MaxPooling2D(64, (2,2), padding='same')(c3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oSngCggBE-L"
      },
      "outputs": [],
      "source": [
        "c4 = Conv2D(256, (4,4), activation='relu')(m3)\n",
        "f1 = Flatten()(c4)\n",
        "d1 = Dense(4096, activation='sigmoid')(f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-mpOOSIBI2k"
      },
      "outputs": [],
      "source": [
        "mod = Model(inputs=[inp], outputs=[d1], name='embedding')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SY5iMcpyBOYY"
      },
      "outputs": [],
      "source": [
        "mod.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBNkHM1gBV2_"
      },
      "outputs": [],
      "source": [
        "def make_embedding():\n",
        "    inp = Input(shape=(100,100,3), name='input_image')\n",
        "\n",
        "    # First block\n",
        "    c1 = Conv2D(64, (10,10), activation='relu')(inp)\n",
        "    m1 = MaxPooling2D(64, (2,2), padding='same')(c1)\n",
        "\n",
        "    # Second block\n",
        "    c2 = Conv2D(128, (7,7), activation='relu')(m1)\n",
        "    m2 = MaxPooling2D(64, (2,2), padding='same')(c2)\n",
        "\n",
        "    # Third block\n",
        "    c3 = Conv2D(128, (4,4), activation='relu')(m2)\n",
        "    m3 = MaxPooling2D(64, (2,2), padding='same')(c3)\n",
        "\n",
        "    # Final embedding block\n",
        "    c4 = Conv2D(256, (4,4), activation='relu')(m3)\n",
        "    f1 = Flatten()(c4)\n",
        "    d1 = Dense(4096, activation='sigmoid')(f1)\n",
        "\n",
        "\n",
        "    return Model(inputs=[inp], outputs=[d1], name='embedding')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYzCtfx4B5iT"
      },
      "outputs": [],
      "source": [
        "embedding = make_embedding()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdwBOr3oB8fW"
      },
      "outputs": [],
      "source": [
        "embedding.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTm0_cKKCX-7"
      },
      "source": [
        "** Build Distance Layer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwH-OjI9Cb-n"
      },
      "outputs": [],
      "source": [
        "# Siamese L1 Distance class\n",
        "class L1Dist(Layer):\n",
        "\n",
        "    # Init method - inheritance\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "    # Magic happens here - similarity calculation\n",
        "    def call(self, input_embedding, validation_embedding):\n",
        "        return tf.math.abs(input_embedding - validation_embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02Mw86nGCglG"
      },
      "outputs": [],
      "source": [
        "l1 = L1Dist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5_WMKKVCkzt"
      },
      "outputs": [],
      "source": [
        "l1(anchor_embedding, validation_embedding)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryvGDaahCr2V"
      },
      "source": [
        "**Make Siamese Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QE8UysnZCx6O"
      },
      "outputs": [],
      "source": [
        "input_image = Input(name='input_img', shape=(100,100,3))\n",
        "validation_image = Input(name='validation_img', shape=(100,100,3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRK7-2nJC2Y3"
      },
      "outputs": [],
      "source": [
        "inp_embedding = embedding(input_image)\n",
        "val_embedding = embedding(validation_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9zlA60iC4lW"
      },
      "outputs": [],
      "source": [
        "siamese_layer = L1Dist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6lcA5jLC6-G"
      },
      "outputs": [],
      "source": [
        "distances = siamese_layer(inp_embedding, val_embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RD-_nZZbC9lX"
      },
      "outputs": [],
      "source": [
        "classifier = Dense(1, activation='sigmoid')(distances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LppCg7DWDBq1"
      },
      "outputs": [],
      "source": [
        "classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZnNRt6wDI8G"
      },
      "outputs": [],
      "source": [
        "siamese_network = Model(inputs=[input_image, validation_image], outputs=classifier, name='SiameseNetwork')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrBszuNKDKW1"
      },
      "outputs": [],
      "source": [
        "siamese_network.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRJ1hRzZDODG"
      },
      "outputs": [],
      "source": [
        "def make_siamese_model():\n",
        "\n",
        "    # Anchor image input in the network\n",
        "    input_image = Input(name='input_img', shape=(100,100,3))\n",
        "\n",
        "    # Validation image in the network\n",
        "    validation_image = Input(name='validation_img', shape=(100,100,3))\n",
        "\n",
        "    # Combine siamese distance components\n",
        "    siamese_layer = L1Dist()\n",
        "    siamese_layer._name = 'distance'\n",
        "    distances = siamese_layer(embedding(input_image), embedding(validation_image))\n",
        "\n",
        "    # Classification layer\n",
        "    classifier = Dense(1, activation='sigmoid')(distances)\n",
        "\n",
        "    return Model(inputs=[input_image, validation_image], outputs=classifier, name='SiameseNetwork')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHyldUh9Daze"
      },
      "outputs": [],
      "source": [
        "siamese_model = make_siamese_model()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UtXxmNTDenf"
      },
      "outputs": [],
      "source": [
        "siamese_model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FslRaKhwDj9L"
      },
      "source": [
        "***TRAINING (SETUP LOSS AND OPTIMIZER) ***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oajt7EBDxmX"
      },
      "outputs": [],
      "source": [
        "binary_cross_loss = tf.losses.BinaryCrossentropy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ii3E8IHWD8yY"
      },
      "outputs": [],
      "source": [
        "opt = tf.keras.optimizers.Adam(1e-4) # 0.0001\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3-KBsv4EAOR"
      },
      "source": [
        "**Checkpoints**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBfY_cPJEIRC"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
        "checkpoint = tf.train.Checkpoint(opt=opt, siamese_model=siamese_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtz6lBWqEQd3"
      },
      "source": [
        "**Train Step Function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRkGaHDdELmE"
      },
      "outputs": [],
      "source": [
        "test_batch = train_data.as_numpy_iterator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hl1NhtUMEYf_"
      },
      "outputs": [],
      "source": [
        "batch_1 = test_batch.next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bv5cXrHPEaZp"
      },
      "outputs": [],
      "source": [
        "X = batch_1[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJf3RdRXEcj0"
      },
      "outputs": [],
      "source": [
        "y = batch_1[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bF9huF02EeuA"
      },
      "outputs": [],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntPgHYP_EgyE"
      },
      "outputs": [],
      "source": [
        "tf.losses.BinaryCrossentropy??"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8RFF69WEyo4"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(batch):\n",
        "\n",
        "    # Record all of our operations\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Get anchor and positive/negative image\n",
        "        X = batch[:2]\n",
        "        # Get label\n",
        "        y = batch[2]\n",
        "\n",
        "        # Forward pass\n",
        "        yhat = siamese_model(X, training=True)\n",
        "        # Calculate loss\n",
        "        loss = binary_cross_loss(y, yhat)\n",
        "    print(loss)\n",
        "\n",
        "    # Calculate gradients\n",
        "    grad = tape.gradient(loss, siamese_model.trainable_variables)\n",
        "\n",
        "    # Calculate updated weights and apply to siamese model\n",
        "    opt.apply_gradients(zip(grad, siamese_model.trainable_variables))\n",
        "\n",
        "    # Return loss\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJDUtu08E1uF"
      },
      "source": [
        "**Training Loop**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtsZ3oazE6dJ"
      },
      "outputs": [],
      "source": [
        "# Importing metric calculations\n",
        "from tensorflow.keras.metrics import Precision, Recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-_KbqbvE_1P"
      },
      "outputs": [],
      "source": [
        "def train(data, EPOCHS):\n",
        "    # Loop through epochs\n",
        "    for epoch in range(1, EPOCHS+1):\n",
        "        print('\\n Epoch {}/{}'.format(epoch, EPOCHS))\n",
        "        progbar = tf.keras.utils.Progbar(len(data))\n",
        "\n",
        "        # Creating a metric object\n",
        "        r = Recall()\n",
        "        p = Precision()\n",
        "\n",
        "        # Loop through each batch\n",
        "        for idx, batch in enumerate(data):\n",
        "            # Run train step here\n",
        "            loss = train_step(batch)\n",
        "            yhat = siamese_model.predict(batch[:2])\n",
        "            r.update_state(batch[2], yhat)\n",
        "            p.update_state(batch[2], yhat)\n",
        "            progbar.update(idx+1)\n",
        "        print(loss.numpy(), r.result().numpy(), p.result().numpy())\n",
        "\n",
        "        # Save checkpoints\n",
        "        if epoch % 10 == 0:\n",
        "            checkpoint.save(file_prefix=checkpoint_prefix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iy8BAILUFFV8"
      },
      "source": [
        "***model traing***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCwH6GguFD1u"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qm6nkLhWFTKx"
      },
      "outputs": [],
      "source": [
        "train(train_data, EPOCHS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVzMjvQ9Faxr"
      },
      "source": [
        "**EVALUATING MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhQWtIeMFgnQ"
      },
      "outputs": [],
      "source": [
        "# Import metric calculations\n",
        "from tensorflow.keras.metrics import Precision, Recall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAZstx4_Ftoc"
      },
      "source": [
        "*** Make Predictions ***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jbh_IsXBF046"
      },
      "outputs": [],
      "source": [
        "# Get a batch of test data\n",
        "test_input, test_val, y_true = test_data.as_numpy_iterator().next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tycXgM0WF8dj"
      },
      "outputs": [],
      "source": [
        "y_hat = siamese_model.predict([test_input, test_val])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIw33CNMF-qn"
      },
      "outputs": [],
      "source": [
        "# Post processing the results\n",
        "[1 if prediction > 0.5 else 0 for prediction in y_hat ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8BKZGgFGAv-"
      },
      "outputs": [],
      "source": [
        "y_true\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuUJtIqjGLuQ"
      },
      "source": [
        "***METRIC CALCULATION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-_jpm_yGKWD"
      },
      "outputs": [],
      "source": [
        "# Creating a metric object\n",
        "m = Recall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exS5GvfSFpZj"
      },
      "outputs": [],
      "source": [
        "# Calculating the recall value\n",
        "m.update_state(y_true, y_hat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBsth21qFW5e"
      },
      "outputs": [],
      "source": [
        "# Return Recall Result\n",
        "m.result().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUVDGSCJGcf-"
      },
      "outputs": [],
      "source": [
        "# Creating a metric object\n",
        "m = Precision()\n",
        "\n",
        "# Calculating the recall value\n",
        "m.update_state(y_true, y_hat)\n",
        "\n",
        "# Return Recall Result\n",
        "m.result().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSF3lQHXGeMM"
      },
      "outputs": [],
      "source": [
        "r = Recall()\n",
        "p = Precision()\n",
        "\n",
        "for test_input, test_val, y_true in test_data.as_numpy_iterator():\n",
        "    yhat = siamese_model.predict([test_input, test_val])\n",
        "    r.update_state(y_true, yhat)\n",
        "    p.update_state(y_true,yhat)\n",
        "\n",
        "print(r.result().numpy(), p.result().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W49qGaeAGi94"
      },
      "outputs": [],
      "source": [
        "# Set plot size\n",
        "plt.figure(figsize=(10,8))\n",
        "\n",
        "# Set first subplot\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(test_input[0])\n",
        "\n",
        "# Set second subplot\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(test_val[0])\n",
        "\n",
        "# Renders cleanly\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5m9DTSpGm3-"
      },
      "source": [
        "**SAVE MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqt-AG4rGqV_"
      },
      "outputs": [],
      "source": [
        "# Save weights\n",
        "siamese_model.save('siamesemodelv2.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7ILgwivGkvw"
      },
      "outputs": [],
      "source": [
        "L1Dist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhJmsldgGvEE"
      },
      "outputs": [],
      "source": [
        "# Reload model\n",
        "siamese_model = tf.keras.models.load_model('siamesemodelv2.h5',\n",
        "                                   custom_objects={'L1Dist':L1Dist, 'BinaryCrossentropy':tf.losses.BinaryCrossentropy})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJkuusRGG5Kq"
      },
      "outputs": [],
      "source": [
        "# Make predictions with reloaded model\n",
        "siamese_model.predict([test_input, test_val])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYXx5VIbHANv"
      },
      "outputs": [],
      "source": [
        "# View model summary\n",
        "siamese_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCfvhCSbHDzK"
      },
      "source": [
        "**REAL TIME TESTING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5573ZsqkHImG"
      },
      "outputs": [],
      "source": [
        "#VERIFICATION FUNCTION\n",
        "application_data\\verification_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5teFQSyjHBDB"
      },
      "outputs": [],
      "source": [
        "os.listdir(os.path.join('application_data', 'verification_images'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufs0557wHVZu"
      },
      "outputs": [],
      "source": [
        "os.path.join('application_data', 'input_image', 'input_image.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gL7m2t7gHYKY"
      },
      "outputs": [],
      "source": [
        "for image in os.listdir(os.path.join('application_data', 'verification_images')):\n",
        "    validation_img = os.path.join('application_data', 'verification_images', image)\n",
        "    print(validation_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MP5uTQpOHbb7"
      },
      "outputs": [],
      "source": [
        "def verify(model, detection_threshold, verification_threshold):\n",
        "    # Build results array\n",
        "    results = []\n",
        "    for image in os.listdir(os.path.join('application_data', 'verification_images')):\n",
        "        input_img = preprocess(os.path.join('application_data', 'input_image', 'input_image.jpg'))\n",
        "        validation_img = preprocess(os.path.join('application_data', 'verification_images', image))\n",
        "\n",
        "        # Make Predictions\n",
        "        result = model.predict(list(np.expand_dims([input_img, validation_img], axis=1)))\n",
        "        results.append(result)\n",
        "\n",
        "    # Detection Threshold: Metric above which a prediciton is considered positive\n",
        "    detection = np.sum(np.array(results) > detection_threshold)\n",
        "\n",
        "    # Verification Threshold: Proportion of positive predictions / total positive samples\n",
        "    verification = detection / len(os.listdir(os.path.join('application_data', 'verification_images')))\n",
        "    verified = verification > verification_threshold\n",
        "\n",
        "    return results, verified"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeV71elqH1bi"
      },
      "source": [
        "*** OpenCV Real Time Verification***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhHLEcQSHtuY"
      },
      "outputs": [],
      "source": [
        "cap = cv2.VideoCapture(4)\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    frame = frame[120:120+250,200:200+250, :]\n",
        "\n",
        "    cv2.imshow('Verification', frame)\n",
        "\n",
        "    # Verification trigger\n",
        "    if cv2.waitKey(10) & 0xFF == ord('v'):\n",
        "        # Save input image to application_data/input_image folder\n",
        "#         hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
        "#         h, s, v = cv2.split(hsv)\n",
        "\n",
        "#         lim = 255 - 10\n",
        "#         v[v > lim] = 255\n",
        "#         v[v <= lim] -= 10\n",
        "\n",
        "#         final_hsv = cv2.merge((h, s, v))\n",
        "#         img = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n",
        "\n",
        "        cv2.imwrite(os.path.join('application_data', 'input_image', 'input_image.jpg'), frame)\n",
        "        # Run verification\n",
        "        results, verified = verify(siamese_model, 0.5, 0.5)\n",
        "        print(verified)\n",
        "\n",
        "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "        break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfKf4hjsIG-R"
      },
      "outputs": [],
      "source": [
        "np.sum(np.squeeze(results) > 0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHZL9Ar2He2b"
      },
      "outputs": [],
      "source": [
        "results"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNKOcp7vTMdU6hMIblxTbYU",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}